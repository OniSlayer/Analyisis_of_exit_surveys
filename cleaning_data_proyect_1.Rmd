---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.3
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
# !ls ./datasets
```

# Cleaning Data Proyect
This proyect have two different data sources: dete_survey and tafe_survey. Each one contains information about the exit surveys conducted to employeed that were about to leave.

The two main questions to answer in this analysis are:
- **Are employees who only worked for the institutes for a short period of time resigning due to some kind of dissatisfaction? What about employees who have been there longer?**
- **Are younger employees resigning due to some kind of dissatisfaction? What about older employees?**



## Importing necessary libraries and loading the datasets

```{python}
# importing necessary libraries
import pandas as pd
import numpy as np
```

```{python}
# reading the datasets
dete_survey = pd.read_csv("datasets/dete_survey.csv")
tafe_survey = pd.read_csv("datasets/tafe_survey.csv")
```

```{python}
# Configure pandas to display all the columns of the datasets
pd.options.display.max_columns = 150
```

## Exploratory analysis

```{python}
# Head of dete dataset and identifying relevant attributes

# Age (categorical, comes in range)
# Cease Date (Categorical)
# Dete Start Date (Categorical)
# SeparationType (categorical, usefull for selecting only Resignations)
# To determine dissatisfaction with the job, the attributes 'Job dissatisfaction', 'dissatisfaction with the department',
# 'Physical work environment', 'Lack of recognition', 'lack of job security', 'work location', 'employmet conditions',
# 'work life balance' and 'workload' will be used. All of them are booleans (True/False)

# There are null values on the selected attributes that will be used in the analysis
dete_survey.head()
```

```{python}
dete_survey.info()
```

```{python}
# Head of tafe dataset and indentification of relevant attributes

# LengthofServiceOverall. Overall Length of Service at Institute (in years) (Categorical, comes as a range)
# CurrentAge (categorical)
# Reason for ceasing employment (usefull for selecting only Ressignations)
# Contributing Factors. Dissatisfaction
# Contributing Factors. Job Dissatisfaction

# There are null values on the selected attributes that will be used in the analysis

tafe_survey.head()
```

```{python}
tafe_survey.info()
```

```{python}
# Selecting only the usefull attributes in the dataframes

selected_tafe =  tafe_survey[[
    'LengthofServiceOverall. Overall Length of Service at Institute (in years)',
    'CurrentAge. Current Age',
    'Reason for ceasing employment',
    'Contributing Factors. Dissatisfaction',
    'Contributing Factors. Job Dissatisfaction',
]].copy()

print(selected_tafe.info())

selected_dete = dete_survey[[
    'Age',
    'Cease Date',
    'DETE Start Date',
    'SeparationType',
    'Job dissatisfaction',
    'Dissatisfaction with the department',
    'Physical work environment',
    'Lack of recognition',
    'Lack of job security',
    'Work location',
    'Employment conditions',
    'Work life balance', 
    'Workload'
]].copy()

print(selected_dete.info())
```

## Cleaning Data


### Null values analysis

```{python}
# A deeper look into the null values by calculating the percent of na values on each attribute

# dete have the most ammount of null values at DETE Start Date, Cease Date and Age 

(selected_dete.isnull().sum()/(selected_dete.shape[0])*100).sort_values(ascending = False)
```

```{python}
# tafe have null values in all the attributes

(selected_tafe.isnull().sum()/(selected_tafe.shape[0])*100).sort_values(ascending = False)
```

```{python}
# Some values on the DETE dataset appear as 'Not Stated', but should be treated as null values

selected_dete['DETE Start Date'].value_counts(dropna = False)
```

```{python}
# Marking null values correctly

print(selected_tafe.isnull().sum().sum())
print(selected_dete.isnull().sum().sum())

selected_dete = selected_dete.replace('Not Stated', np.NaN)

print(selected_tafe.isnull().sum().sum())
print(selected_dete.isnull().sum().sum())

```

### Standarizing and removing characters from column names

```{python}
# Standarizing names that have the same info in both data sets

map_tafe = {
    'CurrentAge. Current Age': 'age',
    'LengthofServiceOverall. Overall Length of Service at Institute (in years)' : 'service_length',
    'Reason for ceasing employment' : 'separation_type',
    'Contributing Factors. Dissatisfaction' : 'dissatisfaction',
    'Contributing Factors. Job Dissatisfaction' : 'job_dissatisfaction'
}

map_dete = {
    'SeparationType' : 'separation_type',
}

selected_tafe.rename(map_tafe, axis = 1, inplace = True)
selected_dete.rename(map_dete, axis = 1, inplace = True)


print(selected_tafe.info())
print(selected_dete.info())
```

```{python}
# Removing spaces, converting to lower case and striping white spaces

selected_tafe.columns = selected_tafe.columns.str.lower().str.strip().str.replace(' ', '_')
selected_dete.columns = selected_dete.columns.str.lower().str.strip().str.replace(' ', '_')

print(selected_tafe.info())
print(selected_dete.info())
```

```{python}
# Directing questions only adress people that resign the job, so a new dataframe with this info is created
# for each dataset, but first is necesssary to unify resignations on the dete dataset

print(selected_dete['separation_type'].value_counts())

selected_dete['separation_type'] = selected_dete['separation_type'].str.split('-').str[0]
```

```{python}
# Selecting only resignations from both datasets

resignations_dete = selected_dete[selected_dete['separation_type'] == "Resignation"].copy()
resignations_tafe = selected_tafe[selected_tafe['separation_type'] == "Resignation"].copy()
```

```{python}
# To create the column of service_length in the dete dataset, it's necessary to extract only the dates from the column
# of cease date

resignations_dete['cease_date'] = resignations_dete['cease_date'].str.split('/').str[-1]
```

```{python}
# Converting the values to float 
resignations_dete['cease_date'] = resignations_dete['cease_date'].astype('float')
resignations_dete['dete_start_date'] = resignations_dete['dete_start_date'].astype('float')
```

```{python}
# Calculating the service_length column for the dete dataset

resignations_dete['service_length'] = (resignations_dete['cease_date'] - resignations_dete['dete_start_date'])
```

```{python}
# looking at outliers in the dete service length dataset
import seaborn as sns
ax = sns.boxplot(x=resignations_dete['service_length'])
```

```{python}
# Unifying the dissatisfaction and the job_dissatisfaction attributes on tafe dataset

def convert_to_bool_dissat(string):
    if string == '-':
        return False
    elif pd.isnull(string):
        return np.nan
    else:
        return True

resignations_tafe['dissatisfied'] = resignations_tafe[['dissatisfaction', 'job_dissatisfaction']].applymap(convert_to_bool_dissat).any(1, skipna = False)
resignations_tafe['dissatisfied'].value_counts(dropna = False)
```

```{python}
# Creating the dissatisfied attribute by using all variables available on the dataset
resignations_dete['dissatisfied'] = resignations_dete[[
    'job_dissatisfaction',
    'dissatisfaction_with_the_department',
    'physical_work_environment',
    'lack_of_recognition',
    'work_location',
    'employment_conditions',
    'work_life_balance',
    'workload'
]].any(1, skipna = False)

resignations_dete['dissatisfied'].value_counts(dropna = False)
```

```{python}
# Adding columns to identify the origin to each dataset
resignations_dete["origin_dataset"] = "DETE"
resignations_tafe["origin_dataset"] = "TAFE"
```

```{python}
# The tafe dataset have the service_length attribute like a range
print(resignations_tafe['service_length'].value_counts())


# The first digit on the interval is extracted with a regex expression
resignations_tafe['service_length'] =  resignations_tafe['service_length'].str.extract(r'(\d+)').astype('float')

# Recheck the values for service_length
print(resignations_tafe['service_length'].value_counts())

```

```{python}
# The ages columns on each dataset don't have the same categories, but it's easy to make them match

print(resignations_tafe['age'].value_counts())
print(resignations_dete['age'].value_counts())

# To make both match, all ages above 56 will be labeled as "56 or older"

def label_old(string):
    if string == "56-60" or string == "61 or older":
        return "56 or older"
    else:
        return string

resignations_dete['age'] = resignations_dete['age'].apply(label_old)

# Then, we remove all double spaces from the tafe dataset and replace them with dashes

resignations_tafe['age'] =  resignations_tafe['age'].str.replace('-', "  ").str.replace("  ", "-")

```

```{python}
# Checking that both datasets have the required values

print(resignations_dete.info())
print('-'*10)
print(resignations_tafe.info())
```

```{python}
# Checking if its possible to drop null values

# Most null values are on service length and age
print(resignations_tafe.isnull().sum().sort_values(ascending = False))
print(resignations_dete.isnull().sum().sort_values(ascending = False))

# Because of this two columns being directly related to the questions, they won't be filled with the average or mode
```

```{python}
# Droping the unecessary attributes before merging the datasets

resignations_tafe.drop(["job_dissatisfaction", "dissatisfaction", "separation_type"], axis = 1, inplace = True)
resignations_dete.drop(["dete_start_date", "cease_date", "workload", "work_life_balance"
                       , "employment_conditions", "work_location", "lack_of_job_security",
                       "lack_of_recognition", "physical_work_environment", "dissatisfaction_with_the_department",
                       "job_dissatisfaction", "separation_type"], axis = 1, inplace = True)

print(resignations_dete.info())
print(resignations_tafe.info())
```

```{python}
# Joining both datasets

combined_resignations = pd.concat([resignations_dete, resignations_tafe], ignore_index = True)
combined_resignations.info()
```

```{python}
# Inspecting null values on the combined dataset

#There are null values on age and service_length
combined_resignations.isnull().sum()

# Most of the rows that don't have a service length are the same that don't have the age (53 out of 55)
combined_resignations[combined_resignations['service_length'].isnull()].isnull().sum()

# Null values are droped given the above fact
print(combined_resignations.info())
combined_resignations.dropna(inplace = True)
print(combined_resignations.info())

```

```{python}
# Creation of bins on the service length years

def make_intervals(number):
    if pd.isnull(number):
        return np.nan
    elif number < 3:
        return "New"
    elif  3<= number <= 6:
        return "Experienced"
    elif 7 <= number <= 10:
        return "Established"
    else:
        return "Veteran"

combined_resignations['service_length_intervals'] = combined_resignations['service_length'].apply(make_intervals)
combined_resignations['service_length_intervals'].value_counts()
```

```{python}
combined_resignations['dissatisfied'].value_counts(dropna = False)
```

```{python}
boli = combined_resignations['service_length_intervals'] == "New"
combined_resignations[boli]['dissatisfied'].mean()
```

```{python}
dissatisfied_by_service_lengt = combined_resignations.pivot_table(index = 'service_length_intervals',values = 'dissatisfied', aggfunc='mean')


```

```{python}
distribution_disatisfied = combined_updated.pivot_table(index='service_cat', values='dissatisfied')
```

```{python}
distribution_disatisfied.plot(kind = 'bar')
```
